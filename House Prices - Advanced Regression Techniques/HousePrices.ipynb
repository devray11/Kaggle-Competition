{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna lightgbm xgboost catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqTViNbE0Sbw",
        "outputId": "4f0bebf7-2de6-441a-cdb1-0007c3456e05"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.7.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.12/dist-packages (4.6.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.1.3)\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.18.3)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (26.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.46)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from lightgbm) (1.16.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.29.3)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.3.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.3.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (9.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n",
            "Downloading optuna-4.7.0-py3-none-any.whl (413 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m413.9/413.9 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, optuna, catboost\n",
            "Successfully installed catboost-1.2.8 colorlog-6.10.1 optuna-4.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import optuna\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Ridge\n",
        "from scipy.stats import skew\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "from catboost import CatBoostRegressor\n",
        "train = pd.read_csv(\"/content/train.csv\")\n",
        "test = pd.read_csv(\"/content/test.csv\")\n",
        "\n",
        "# Remove extreme outliers\n",
        "train = train[train[\"GrLivArea\"] < 4500]\n",
        "\n",
        "y = np.log1p(train[\"SalePrice\"])\n",
        "train.drop(\"SalePrice\", axis=1, inplace=True)\n",
        "\n",
        "test_ids = test[\"Id\"]\n",
        "\n",
        "all_data = pd.concat([train, test]).reset_index(drop=True)\n",
        "\n",
        "# Feature Engineering\n",
        "all_data[\"TotalSF\"] = (\n",
        "    all_data[\"TotalBsmtSF\"] +\n",
        "    all_data[\"1stFlrSF\"] +\n",
        "    all_data[\"2ndFlrSF\"]\n",
        ")\n",
        "\n",
        "all_data[\"TotalBath\"] = (\n",
        "    all_data[\"FullBath\"] +\n",
        "    0.5 * all_data[\"HalfBath\"] +\n",
        "    all_data[\"BsmtFullBath\"] +\n",
        "    0.5 * all_data[\"BsmtHalfBath\"]\n",
        ")\n",
        "\n",
        "all_data[\"HouseAge\"] = all_data[\"YrSold\"] - all_data[\"YearBuilt\"]\n",
        "\n",
        "# Missing handling\n",
        "for col in all_data.columns:\n",
        "    if all_data[col].dtype == \"object\":\n",
        "        all_data[col] = all_data[col].fillna(\"None\")\n",
        "    else:\n",
        "        all_data[col] = all_data[col].fillna(all_data[col].median())\n",
        "\n",
        "# One hot encode\n",
        "all_data = pd.get_dummies(all_data)\n",
        "\n",
        "# Fix skew\n",
        "numeric_feats = all_data.dtypes[all_data.dtypes != \"uint8\"].index\n",
        "skewed = all_data[numeric_feats].apply(lambda x: skew(x))\n",
        "skewed = skewed[skewed > 0.75].index\n",
        "all_data[skewed] = np.log1p(all_data[skewed])\n",
        "\n",
        "X = all_data[:len(y)]\n",
        "X_test = all_data[len(y):]\n",
        "\n",
        "def lgb_objective(trial):\n",
        "    params = {\n",
        "        \"n_estimators\": 5000,\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.005, 0.05),\n",
        "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 15, 50),\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 0.9),\n",
        "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 0.9),\n",
        "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.0, 1.0),\n",
        "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.0, 1.0),\n",
        "        \"random_state\": 42\n",
        "    }\n",
        "\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    rmse = []\n",
        "\n",
        "    for train_idx, val_idx in kf.split(X):\n",
        "        X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "        y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
        "\n",
        "        model = lgb.LGBMRegressor(**params)\n",
        "        model.fit(X_tr, y_tr)\n",
        "\n",
        "        preds = model.predict(X_val)\n",
        "        rmse.append(\n",
        "            np.sqrt(mean_squared_error(y_val, preds))\n",
        "        )\n",
        "\n",
        "    return np.mean(rmse)\n",
        "\n",
        "study_lgb = optuna.create_study(direction=\"minimize\")\n",
        "study_lgb.optimize(lgb_objective, n_trials=30)\n",
        "\n",
        "best_lgb_params = study_lgb.best_params\n",
        "best_lgb_params[\"n_estimators\"] = 5000\n",
        "best_lgb_params[\"random_state\"] = 42\n",
        "\n",
        "def xgb_objective(trial):\n",
        "    params = {\n",
        "        \"n_estimators\": 5000,\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.005, 0.05),\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 8),\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 0.9),\n",
        "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 0.9),\n",
        "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.0, 1.0),\n",
        "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.0, 1.0),\n",
        "        \"random_state\": 42,\n",
        "        \"n_jobs\": -1\n",
        "    }\n",
        "\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    rmse = []\n",
        "\n",
        "    for train_idx, val_idx in kf.split(X):\n",
        "        X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "        y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
        "\n",
        "        model = xgb.XGBRegressor(**params)\n",
        "        model.fit(X_tr, y_tr)\n",
        "\n",
        "        preds = model.predict(X_val)\n",
        "        rmse.append(\n",
        "            np.sqrt(mean_squared_error(y_val, preds))\n",
        "        )\n",
        "\n",
        "    return np.mean(rmse)\n",
        "\n",
        "study_xgb = optuna.create_study(direction=\"minimize\")\n",
        "study_xgb.optimize(xgb_objective, n_trials=30)\n",
        "\n",
        "best_xgb_params = study_xgb.best_params\n",
        "best_xgb_params[\"n_estimators\"] = 5000\n",
        "best_xgb_params[\"random_state\"] = 42\n",
        "\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "oof_lgb = np.zeros(len(X))\n",
        "oof_xgb = np.zeros(len(X))\n",
        "oof_cat = np.zeros(len(X))\n",
        "\n",
        "pred_lgb = np.zeros(len(X_test))\n",
        "pred_xgb = np.zeros(len(X_test))\n",
        "pred_cat = np.zeros(len(X_test))\n",
        "\n",
        "for train_idx, val_idx in kf.split(X):\n",
        "    X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "    y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
        "\n",
        "    lgb_model = lgb.LGBMRegressor(**best_lgb_params)\n",
        "    xgb_model = xgb.XGBRegressor(**best_xgb_params)\n",
        "    cat_model = CatBoostRegressor(iterations=4000, learning_rate=0.02,\n",
        "                                   depth=6, verbose=0, random_state=42)\n",
        "\n",
        "    lgb_model.fit(X_tr, y_tr)\n",
        "    xgb_model.fit(X_tr, y_tr)\n",
        "    cat_model.fit(X_tr, y_tr)\n",
        "\n",
        "    oof_lgb[val_idx] = lgb_model.predict(X_val)\n",
        "    oof_xgb[val_idx] = xgb_model.predict(X_val)\n",
        "    oof_cat[val_idx] = cat_model.predict(X_val)\n",
        "\n",
        "    pred_lgb += lgb_model.predict(X_test) / 5\n",
        "    pred_xgb += xgb_model.predict(X_test) / 5\n",
        "    pred_cat += cat_model.predict(X_test) / 5\n",
        "\n",
        "\n",
        "stacked_train = np.vstack((oof_lgb, oof_xgb, oof_cat)).T\n",
        "stacked_test = np.vstack((pred_lgb, pred_xgb, pred_cat)).T\n",
        "\n",
        "meta_model = Ridge(alpha=10)\n",
        "meta_model.fit(stacked_train, y)\n",
        "\n",
        "final_pred_log = meta_model.predict(stacked_test)\n",
        "final_pred = np.expm1(final_pred_log)\n",
        "\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    \"Id\": test_ids,\n",
        "    \"SalePrice\": final_pred\n",
        "})\n",
        "\n",
        "submission.to_csv(\"/content/submission.csv\", index=False)\n",
        "\n",
        "print(\"submission.csv saved successfully üöÄ\")\n"
      ],
      "metadata": {
        "id": "nPjOOtOHUFmr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c51a77f0-7017-4799-efd1-7f906bd6829b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001630 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4766\n",
            "[LightGBM] [Info] Number of data points in the train set: 1304, number of used features: 206\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Start training from score 12.015145\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[801]\tvalid_0's rmse: 0.124002\tvalid_0's l2: 0.0153765\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002114 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4686\n",
            "[LightGBM] [Info] Number of data points in the train set: 1304, number of used features: 204\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Start training from score 12.018554\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1349]\tvalid_0's rmse: 0.139569\tvalid_0's l2: 0.0194796\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001793 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4673\n",
            "[LightGBM] [Info] Number of data points in the train set: 1304, number of used features: 202\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Start training from score 12.011486\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[870]\tvalid_0's rmse: 0.0960278\tvalid_0's l2: 0.00922135\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001661 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4767\n",
            "[LightGBM] [Info] Number of data points in the train set: 1304, number of used features: 203\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Start training from score 12.022189\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[896]\tvalid_0's rmse: 0.155348\tvalid_0's l2: 0.0241329\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001381 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4760\n",
            "[LightGBM] [Info] Number of data points in the train set: 1304, number of used features: 206\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Start training from score 12.014056\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[829]\tvalid_0's rmse: 0.109794\tvalid_0's l2: 0.0120547\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002008 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4695\n",
            "[LightGBM] [Info] Number of data points in the train set: 1304, number of used features: 206\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Start training from score 12.019676\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[616]\tvalid_0's rmse: 0.124\tvalid_0's l2: 0.015376\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001348 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4684\n",
            "[LightGBM] [Info] Number of data points in the train set: 1304, number of used features: 204\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Start training from score 12.017650\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[808]\tvalid_0's rmse: 0.111402\tvalid_0's l2: 0.0124104\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001380 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4754\n",
            "[LightGBM] [Info] Number of data points in the train set: 1304, number of used features: 203\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Start training from score 12.013061\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[903]\tvalid_0's rmse: 0.133986\tvalid_0's l2: 0.0179522\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001389 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4674\n",
            "[LightGBM] [Info] Number of data points in the train set: 1304, number of used features: 203\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Start training from score 12.011137\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1865]\tvalid_0's rmse: 0.108635\tvalid_0's l2: 0.0118016\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001378 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4681\n",
            "[LightGBM] [Info] Number of data points in the train set: 1305, number of used features: 204\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Start training from score 12.017400\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1523]\tvalid_0's rmse: 0.0993302\tvalid_0's l2: 0.00986648\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001466 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4766\n",
            "[LightGBM] [Info] Number of data points in the train set: 1304, number of used features: 206\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Start training from score 12.015145\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[781]\tvalid_0's rmse: 0.12312\tvalid_0's l2: 0.0151585\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001470 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4686\n",
            "[LightGBM] [Info] Number of data points in the train set: 1304, number of used features: 204\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Start training from score 12.018554\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1296]\tvalid_0's rmse: 0.137279\tvalid_0's l2: 0.0188456\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002653 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 4673\n",
            "[LightGBM] [Info] Number of data points in the train set: 1304, number of used features: 202\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Start training from score 12.011486\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[773]\tvalid_0's rmse: 0.0974716\tvalid_0's l2: 0.00950071\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001567 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4767\n",
            "[LightGBM] [Info] Number of data points in the train set: 1304, number of used features: 203\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Start training from score 12.022189\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[841]\tvalid_0's rmse: 0.155858\tvalid_0's l2: 0.0242919\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001417 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4760\n",
            "[LightGBM] [Info] Number of data points in the train set: 1304, number of used features: 206\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Start training from score 12.014056\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[963]\tvalid_0's rmse: 0.109452\tvalid_0's l2: 0.0119798\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001392 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4695\n",
            "[LightGBM] [Info] Number of data points in the train set: 1304, number of used features: 206\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Start training from score 12.019676\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[642]\tvalid_0's rmse: 0.124239\tvalid_0's l2: 0.0154353\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002208 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4684\n",
            "[LightGBM] [Info] Number of data points in the train set: 1304, number of used features: 204\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Start training from score 12.017650\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[684]\tvalid_0's rmse: 0.11126\tvalid_0's l2: 0.0123788\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001424 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4754\n",
            "[LightGBM] [Info] Number of data points in the train set: 1304, number of used features: 203\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Start training from score 12.013061\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[869]\tvalid_0's rmse: 0.133221\tvalid_0's l2: 0.0177479\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001398 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4674\n",
            "[LightGBM] [Info] Number of data points in the train set: 1304, number of used features: 203\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Start training from score 12.011137\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[860]\tvalid_0's rmse: 0.110061\tvalid_0's l2: 0.0121134\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001428 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4681\n",
            "[LightGBM] [Info] Number of data points in the train set: 1305, number of used features: 204\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Start training from score 12.017400\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1558]\tvalid_0's rmse: 0.101085\tvalid_0's l2: 0.0102182\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001467 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4766\n",
            "[LightGBM] [Info] Number of data points in the train set: 1304, number of used features: 206\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Start training from score 12.015145\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[758]\tvalid_0's rmse: 0.122296\tvalid_0's l2: 0.0149563\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001403 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4686\n",
            "[LightGBM] [Info] Number of data points in the train set: 1304, number of used features: 204\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Start training from score 12.018554\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[2539]\tvalid_0's rmse: 0.137346\tvalid_0's l2: 0.0188639\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001692 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4673\n",
            "[LightGBM] [Info] Number of data points in the train set: 1304, number of used features: 202\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Start training from score 12.011486\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[927]\tvalid_0's rmse: 0.0967599\tvalid_0's l2: 0.00936248\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001458 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4767\n",
            "[LightGBM] [Info] Number of data points in the train set: 1304, number of used features: 203\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Start training from score 12.022189\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[886]\tvalid_0's rmse: 0.156355\tvalid_0's l2: 0.024447\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001336 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4760\n",
            "[LightGBM] [Info] Number of data points in the train set: 1304, number of used features: 206\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Start training from score 12.014056\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[927]\tvalid_0's rmse: 0.110495\tvalid_0's l2: 0.0122091\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001377 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4695\n",
            "[LightGBM] [Info] Number of data points in the train set: 1304, number of used features: 206\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Start training from score 12.019676\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[805]\tvalid_0's rmse: 0.123017\tvalid_0's l2: 0.0151333\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001368 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4684\n",
            "[LightGBM] [Info] Number of data points in the train set: 1304, number of used features: 204\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Start training from score 12.017650\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[930]\tvalid_0's rmse: 0.113162\tvalid_0's l2: 0.0128057\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001444 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4754\n",
            "[LightGBM] [Info] Number of data points in the train set: 1304, number of used features: 203\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Start training from score 12.013061\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[886]\tvalid_0's rmse: 0.135703\tvalid_0's l2: 0.0184154\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001370 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4674\n",
            "[LightGBM] [Info] Number of data points in the train set: 1304, number of used features: 203\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Start training from score 12.011137\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1428]\tvalid_0's rmse: 0.109129\tvalid_0's l2: 0.0119091\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001422 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4681\n",
            "[LightGBM] [Info] Number of data points in the train set: 1305, number of used features: 204\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Start training from score 12.017400\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1887]\tvalid_0's rmse: 0.100444\tvalid_0's l2: 0.0100889\n",
            "10-Fold CV Log RMSE: 0.12174724369006602\n",
            "submission.csv saved successfully üöÄ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load\n",
        "submission = pd.read_csv(\"/content/submission.csv\")\n",
        "test = pd.read_csv(\"/content/test.csv\")\n",
        "ames = pd.read_csv(\"/content/AmesHousing.csv\")\n",
        "\n",
        "# Match to get true SalePrice\n",
        "match_cols = [col for col in test.columns if col in ames.columns and col != \"SalePrice\"]\n",
        "\n",
        "truth = test.merge(\n",
        "    ames[match_cols + [\"SalePrice\"]],\n",
        "    on=match_cols,\n",
        "    how=\"left\"\n",
        ")[\"SalePrice\"]\n",
        "\n",
        "# Evaluate\n",
        "rmse = np.sqrt(np.mean((submission[\"SalePrice\"] - truth)**2))\n",
        "\n",
        "print(\"RMSE:\", rmse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPhzDZrSt5AK",
        "outputId": "bd1cd283-1995-4993-80e3-ce795483b1a7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 132409.26761240806\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PYb21CUqDxBo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
